{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "176f9bda-eba5-4d5b-8cb9-55d01581575b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf #tensorflow is for building and training deep learning models\n",
    "from tensorflow import keras #for simplifying building and training \n",
    "from tensorflow.keras import datasets,models,layers\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline \n",
    "#specifies that Matplotlib plots should be displayed directly in the notebook output cell rather than in a separate window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "469fc856-12f2-41e4-a90d-a3dc5f602fdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train,y_train),(x_test,y_test)=keras.datasets.mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a8ad2ae7-1984-4bbb-9084-9fd31eebee52",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60000"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(x_train)  #no. of images in training dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e3f0644d-45a6-4117-a9bd-0068f96d8bc3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(x_test) #no. of images in testing dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6ee26cd2-b4cb-46fe-8e83-59bdb45c259a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28, 28)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train[0].shape #every image is of 28x28 pixel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "564b470c-da91-4b44-bf56-a5d7618f9a4c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(x_train[0].shape) #shape depicts that image is greyscale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b35df95c-ac34-4c67-8389-603cb1a323a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#scaling the dataset for better accuracy\n",
    "x_train=x_train/255\n",
    "x_test=x_test/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a7b66b27-8906-42cc-ad35-4201a696c07e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5, 0, 4, ..., 5, 6, 8], dtype=uint8)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f268d021-c991-44e1-a8d2-a07f9f32fa81",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.01176471, 0.07058824, 0.07058824,\n",
       "        0.07058824, 0.49411765, 0.53333333, 0.68627451, 0.10196078,\n",
       "        0.65098039, 1.        , 0.96862745, 0.49803922, 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.11764706, 0.14117647,\n",
       "        0.36862745, 0.60392157, 0.66666667, 0.99215686, 0.99215686,\n",
       "        0.99215686, 0.99215686, 0.99215686, 0.88235294, 0.6745098 ,\n",
       "        0.99215686, 0.94901961, 0.76470588, 0.25098039, 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.19215686, 0.93333333, 0.99215686,\n",
       "        0.99215686, 0.99215686, 0.99215686, 0.99215686, 0.99215686,\n",
       "        0.99215686, 0.99215686, 0.98431373, 0.36470588, 0.32156863,\n",
       "        0.32156863, 0.21960784, 0.15294118, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.07058824, 0.85882353, 0.99215686,\n",
       "        0.99215686, 0.99215686, 0.99215686, 0.99215686, 0.77647059,\n",
       "        0.71372549, 0.96862745, 0.94509804, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.31372549, 0.61176471,\n",
       "        0.41960784, 0.99215686, 0.99215686, 0.80392157, 0.04313725,\n",
       "        0.        , 0.16862745, 0.60392157, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.05490196,\n",
       "        0.00392157, 0.60392157, 0.99215686, 0.35294118, 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.54509804, 0.99215686, 0.74509804, 0.00784314,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.04313725, 0.74509804, 0.99215686, 0.2745098 ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.1372549 , 0.94509804, 0.88235294,\n",
       "        0.62745098, 0.42352941, 0.00392157, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.31764706, 0.94117647,\n",
       "        0.99215686, 0.99215686, 0.46666667, 0.09803922, 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.17647059,\n",
       "        0.72941176, 0.99215686, 0.99215686, 0.58823529, 0.10588235,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.0627451 , 0.36470588, 0.98823529, 0.99215686, 0.73333333,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.97647059, 0.99215686, 0.97647059,\n",
       "        0.25098039, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.18039216,\n",
       "        0.50980392, 0.71764706, 0.99215686, 0.99215686, 0.81176471,\n",
       "        0.00784314, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.15294118, 0.58039216, 0.89803922,\n",
       "        0.99215686, 0.99215686, 0.99215686, 0.98039216, 0.71372549,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.09411765, 0.44705882, 0.86666667, 0.99215686, 0.99215686,\n",
       "        0.99215686, 0.99215686, 0.78823529, 0.30588235, 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.09019608, 0.25882353,\n",
       "        0.83529412, 0.99215686, 0.99215686, 0.99215686, 0.99215686,\n",
       "        0.77647059, 0.31764706, 0.00784314, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.07058824, 0.67058824, 0.85882353, 0.99215686,\n",
       "        0.99215686, 0.99215686, 0.99215686, 0.76470588, 0.31372549,\n",
       "        0.03529412, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.21568627,\n",
       "        0.6745098 , 0.88627451, 0.99215686, 0.99215686, 0.99215686,\n",
       "        0.99215686, 0.95686275, 0.52156863, 0.04313725, 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.53333333,\n",
       "        0.99215686, 0.99215686, 0.99215686, 0.83137255, 0.52941176,\n",
       "        0.51764706, 0.0627451 , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "413ae3d6-c707-4a59-b194-e535ed46ac91",
   "metadata": {},
   "outputs": [],
   "source": [
    "#the above cell shows that each image represents a 2D array with values between 0 and 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6a6db6ef-909b-42e4-9c94-06df3e3d692b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x26229c7da90>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 480x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.matshow(x_train[5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "60476d46-3809-40b5-8ba6-5a4cdac4506d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d71c9700-82a2-484a-b325-8f8ac0856b57",
   "metadata": {},
   "source": [
    "## First creating an ANN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f6e8b025-d329-4568-a2fb-256d8ae739b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vishw\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\reshaping\\flatten.py:37: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step - accuracy: 0.8757 - loss: 0.4463\n",
      "Epoch 2/5\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.9605 - loss: 0.1361\n",
      "Epoch 3/5\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9740 - loss: 0.0883\n",
      "Epoch 4/5\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9808 - loss: 0.0635\n",
      "Epoch 5/5\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.9838 - loss: 0.0518\n",
      "Accuracy: 98.37499856948853 %\n"
     ]
    }
   ],
   "source": [
    "ann_model=models.Sequential([\n",
    "    layers.Flatten(input_shape=(28,28)), #we have specify the input shape for first layer\n",
    "    layers.Dense(100,activation='relu'), #relu helps in non linearity. it gives zero for negative values and the number itself for positive numbers\n",
    "    layers.Dense(10,activation='sigmoid')\n",
    "])\n",
    "ann_model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ") # When compiling your model, you specify sparse_categorical_crossentropy as the loss function if your target labels are integers. Additionally, you usually specify 'accuracy' as a metric to monitor during training.\n",
    "history=ann_model.fit(x_train,y_train,epochs=5)\n",
    "final_accuracy = history.history['accuracy'][-1]\n",
    "print(\"Accuracy:\", final_accuracy * 100, \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b92be2c7-3021-4dd9-b5e1-ac48a8ca8320",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9682 - loss: 0.1024\n",
      "accuracy: 97.35000133514404\n"
     ]
    }
   ],
   "source": [
    "loss,accuracy=ann_model.evaluate(x_test,y_test)\n",
    "print(\"accuracy:\",accuracy*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a8df1f2c-8d90-4989-8d3b-9f39f0ca11d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 784)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_flat=x_train.reshape(len(x_train),28*28)\n",
    "x_test_flat=x_test.reshape(len(x_test),28*28)\n",
    "x_train_flat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e340647e-6f2f-46be-8cb3-1a2e59db524c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
      "[3.2277264e-02 2.5202597e-02 4.6741503e-01 9.9264741e-01 8.8632278e-06\n",
      " 4.0385593e-02 7.8535663e-07 9.9999404e-01 2.1225352e-02 4.0965170e-01]\n"
     ]
    }
   ],
   "source": [
    "y_predict=ann_model.predict(x_test)\n",
    "print(y_predict[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85b66904-8d7d-4556-8a5e-f821251785da",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5616bb73-a250-4502-8888-e2dc8bc33298",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
      "classification report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.99      0.99       980\n",
      "           1       0.98      0.99      0.98      1135\n",
      "           2       0.98      0.97      0.98      1032\n",
      "           3       0.93      0.99      0.96      1010\n",
      "           4       0.98      0.97      0.98       982\n",
      "           5       0.98      0.97      0.97       892\n",
      "           6       0.98      0.98      0.98       958\n",
      "           7       0.97      0.98      0.97      1028\n",
      "           8       0.98      0.95      0.96       974\n",
      "           9       0.98      0.94      0.96      1009\n",
      "\n",
      "    accuracy                           0.97     10000\n",
      "   macro avg       0.97      0.97      0.97     10000\n",
      "weighted avg       0.97      0.97      0.97     10000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix , classification_report\n",
    "y_predict=ann_model.predict(x_test)\n",
    "y_predict_class=[np.argmax(element) for element in y_predict] # gives the element that has the the highest activation in each prediction\n",
    "print(\"classification report: \\n\",classification_report(y_test,y_predict_class))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d8a9bfb-93fc-4c9c-b571-507f512d0e0f",
   "metadata": {},
   "source": [
    "## Now let's make a CNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b1f0d9b6-30c2-4f0b-ad25-1633ff64778d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vishw\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "cnn_model=models.Sequential([\n",
    "    #feature extrction(cnn):\n",
    "    layers.Conv2D(filters=32,kernel_size=(3,3),activation='relu',input_shape=(28,28,1)),#we have specify the input shape for first layer\n",
    "    layers.MaxPooling2D((2,2)),\n",
    "\n",
    "    layers.Conv2D(filters=64,kernel_size=(3,3),activation='relu'),\n",
    "    layers.MaxPooling2D((2,2)),\n",
    "\n",
    "    layers.Conv2D(filters=128,kernel_size=(3,3),activation='relu'),\n",
    "    layers.MaxPooling2D((2,2)),\n",
    "    #classification(dense):\n",
    "    layers.Flatten(), #we have specify the input shape for first layer\n",
    "    layers.Dense(100,activation='relu'), #relu helps in non linearity. it gives zero for negative values and the number itself for positive numbers\n",
    "    layers.Dense(10,activation='softmax') #here we have use softmax its help us to normalise\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0c1dbcac-1326-4cfd-b22a-3685c35e7057",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "14b9956d-5e96-44b8-aea1-4a12a48a9ca0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 29ms/step - accuracy: 0.8773 - loss: 0.3986\n",
      "Epoch 2/5\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 31ms/step - accuracy: 0.9786 - loss: 0.0701\n",
      "Epoch 3/5\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 32ms/step - accuracy: 0.9856 - loss: 0.0464\n",
      "Epoch 4/5\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 31ms/step - accuracy: 0.9880 - loss: 0.0342\n",
      "Epoch 5/5\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 29ms/step - accuracy: 0.9912 - loss: 0.0260\n"
     ]
    }
   ],
   "source": [
    "history1=cnn_model.fit(x_train,y_train,epochs=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "693e010a-1997-4de3-8d9e-fea363105c79",
   "metadata": {},
   "source": [
    "#### accuracy on train dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "38acb0fd-bea6-4c30-a031-f8d6fb455a95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 99.08000230789185 %\n"
     ]
    }
   ],
   "source": [
    "final_accuracy = history1.history['accuracy'][-1]\n",
    "print(\"Accuracy:\", final_accuracy * 100, \"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0eaa961d-72c7-484c-869a-c1345111dd9c",
   "metadata": {},
   "source": [
    "#### accuracy on test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ce5d4ad6-5cc3-44ad-b99c-f33be1bf1e9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9826 - loss: 0.0635\n",
      "accuracy: 98.65000247955322\n"
     ]
    }
   ],
   "source": [
    "loss,accuracy=cnn_model.evaluate(x_test,y_test)\n",
    "print(\"accuracy:\",accuracy*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "51434d9f-cefd-4314-b32e-876d0034b485",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step\n",
      "classification report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.98      0.99       980\n",
      "           1       1.00      0.99      1.00      1135\n",
      "           2       1.00      0.98      0.99      1032\n",
      "           3       0.99      0.99      0.99      1010\n",
      "           4       1.00      0.97      0.99       982\n",
      "           5       0.96      0.99      0.98       892\n",
      "           6       0.99      0.99      0.99       958\n",
      "           7       0.98      0.99      0.99      1028\n",
      "           8       0.99      0.99      0.99       974\n",
      "           9       0.98      0.98      0.98      1009\n",
      "\n",
      "    accuracy                           0.99     10000\n",
      "   macro avg       0.99      0.99      0.99     10000\n",
      "weighted avg       0.99      0.99      0.99     10000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix , classification_report\n",
    "y_predict=cnn_model.predict(x_test)\n",
    "y_predict_class=[np.argmax(element) for element in y_predict] # gives the element that has the the highest activation in each prediction\n",
    "print(\"classification report: \\n\",classification_report(y_test,y_predict_class))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3d4188c-e309-44b7-a966-745c83a8dfce",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
