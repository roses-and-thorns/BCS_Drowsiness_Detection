CLASSIFICATION OF SIGNALS 
• Classification of biomedical signals is essential in building BrainComputer Interfaces (BCIs) to distinguish between different mental 
actions. By classifying brain signals, we can equalize certain sets of 
extracted features to correspond to certain commands.
• Classification is the process of categorization of electrical activity 
measured by our recording device. It is the process of grouping 
values of a set based on a property that all values in that set share.
Whereas a classifier is a computational tool,used to obtain 
classification. 
• The more complex a classifier is, the more classifications one can 
achieve. However we must also look into the computational 
requirements of the chosen classifier.
• We transform EEG data into a feature vector. Then it’s ready for 
classification.
• There are different classification algorithms, we’ll study 4 of them.
1. Linear classification:-
Linear classifiers are discriminant algorithms that use linear 
functions to distinguish classes. We have 2 techniques:
• LDA- It uses a hyperplane to separate the classes. It 
requires very low computational power, but its linearity 
provides poor results on complex EEG signals.
• SVM- Uses discriminant hyperplanes to identify classes. To 
find the best straight line, we define classifier margin. 
Classifier margin of a linear classifier is the width by which 
the boundry can be increased by before hitting other data 
points. The line with the max classifier margin is the best 
classifier line.
2. Neural Network:-
Neural networks use multilayer perceptrons. Neural networks learn 
by adjusting several weights and biases which tend to minimize a 
certain loss function using the algorithm of backpropagation. The set 
of weights and biases that produces the minimum loss is selected 
and the network is said to be trained.
3. Nonlinear Bayesian Classifiers:-
There are basically two types of nonliear Bayesian classifiers in use 
for BCI systems. 
1. Bayes quadratic: They work by producing non-linear boundaries. It 
works using probability calculation for each class and assigns the 
higher probability to the feature map from where it belongs. 
2. Hidden markov model: It is good classifier of time series(thus 
good for EEG) HMM can be seen as a kind of probabilistic automaton 
that can provide the probability of observing a given sequence of 
feature vectors. 
4. Nearest Neighbour Classifiers:-
The models assign a feature vector to a class according to its nearest 
neighbour(s). The neighbour can be a feature vector from the training 
set as in the case of k-nearest neighbours (k-NN). In case of using 
kNN, the aim is to assign an unknown data point in the dominating 
class among its k-NN, with in the training set. In BCI the nearest 
neighbour are obtained by metric distance(MD)
Lastly, we can combine the above classifiers to improve performance of 
the BCI system
